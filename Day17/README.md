# ðŸ”» Day 17 â€” PCA (Dimensionality Reduction)

### ðŸŽ¯ Objective
Understand **Principal Component Analysis (PCA)** and reduce Iris dataset dimensions from 4 â†’ 2 while preserving maximum variance.

---

## ðŸ“˜ Topics Covered

### 1. What is PCA?
PCA is a linear dimensionality reduction technique that:
- Rotates the data  
- Creates new axes (principal components)  
- Captures the **maximum variance** in fewer dimensions  

### 2. Why PCA?
- Faster ML models  
- Removes multicollinearity  
- Better visualization (2D/3D)  
- Noise reduction  

### 3. Explained Variance Ratio
Shows how much information each principal component retains.

Example:
| PC | Variance |
|----|-----------|
| PC1 | 92% |
| PC2 | 5% |

