# âš–ï¸ Day 23 â€” Imbalanced Data (SMOTE + Class Weights)

### ğŸ¯ Objective
Learn techniques to handle **imbalanced datasets**, where one class is significantly smaller than the other.  
You will implement:
- Logistic Regression on imbalanced data
- **SMOTE** (Synthetic Minority Oversampling Technique)
- **Class Weights** adjustment
- Visual comparison before/after oversampling

---

## ğŸ“˜ Topics Covered

### 1. What is Imbalanced Data?
A dataset where the distribution of target classes is uneven.  
Example:
- Class 0 â†’ 90%
- Class 1 â†’ 10%

This causes the model to predict mostly the majority class.

---

## âŒ Problem Without Fixing Imbalance
- High accuracy but BAD recall for minority class  
- Confusion matrix showing incorrect behavior  
- Model becomes biased toward majority class  

---

## âœ”ï¸ Method 1 â€” SMOTE (Oversampling)
SMOTE generates synthetic samples for the minority class:
Advantages:
- Works well for numeric data  
- Prevents overfitting more than random oversampling  

---

## âœ”ï¸ Method 2 â€” Class Weights
Use model parameter:
This makes the model pay **more attention** to minority samples during training.



