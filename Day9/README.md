# ðŸ“Š Day 09 â€” Model Metrics & Evaluation (Deep Dive)

### ðŸŽ¯ Objective
Evaluate ML models beyond accuracy â€” using **precision, recall, F1-score, ROC, and AUC** to understand performance in real-world conditions.

---

## ðŸ“˜ Topics Covered
1. **Confusion Matrix**
   - Shows modelâ€™s classification summary  
   - Metrics derived from it:
     - **Accuracy** = (TP + TN) / (TP + TN + FP + FN)  
     - **Precision** = TP / (TP + FP)  
     - **Recall (Sensitivity)** = TP / (TP + FN)  
     - **F1-Score** = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)

2. **ROC & AUC**
   - ROC = Receiver Operating Characteristic  
   - AUC = Area Under Curve (measures modelâ€™s ability to separate classes)

3. **Precision-Recall Tradeoff**
   - Adjusting classification threshold changes precision and recall balance  

---

## ðŸ§  Why This Matters
Different models may have the same accuracy but vary greatly in recall or precision â€”  
especially critical for applications like:
- Medical diagnosis (high recall)
- Fraud detection (high precision)

---